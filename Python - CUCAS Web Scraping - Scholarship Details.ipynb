{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import bs4\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url):\n",
    "    r = requests.get(url) #returns the HTML of the page, can be done through urlopen as well\n",
    "    soup = bs4.BeautifulSoup(r.content)\n",
    "    \n",
    "    titles = soup.findAll(\"td\",{\"style\":\"border:0 none;padding:0;background:0 none;\"})\n",
    "    titles = titles[1:len(titles):2]\n",
    "    \n",
    "    majors = soup.findAll(\"td\",{\"width\":\"135\"})\n",
    "    \n",
    "    languages = soup.findAll(\"td\",{\"width\":\"105\"})\n",
    "    \n",
    "    start = soup.findAll(\"td\",{\"width\":\"120\"})\n",
    "    start = start[0:len(start):2]\n",
    "    \n",
    "    scholarship = soup.findAll(\"td\",{\"width\":\"212\"})\n",
    "    \n",
    "    to_pay = soup.findAll(\"td\",{\"width\":\"262\"})\n",
    "    \n",
    "    return titles, majors, languages, start, scholarship, to_pay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_count(url):\n",
    "    url = url + str(1)\n",
    "    r = requests.get(url) #returns the HTML of the page, can be done through urlopen as well\n",
    "    soup = bs4.BeautifulSoup(r.content)\n",
    "    page_numbers = soup.findAll(\"div\",{\"class\":\"page\"})\n",
    "    total_schols = int(page_numbers[0].text[page_numbers[0].text.find(':')+1:])\n",
    "    print('ttl page ' + str(total_schols))\n",
    "    if (total_schols%15==0):\n",
    "        iterations = total_schols/15\n",
    "    else:\n",
    "        iterations = int(total_schols/15)+1\n",
    "    return(int(iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttl page 62\n",
      "ttl page 1390\n",
      "ttl page 1461\n",
      "ttl page 692\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dict = {}\n",
    "schol_id=0\n",
    "with open('test_new.csv', 'w', newline='',encoding=\"utf-8\") as fp:\n",
    "    a = csv.writer(fp, delimiter=',')\n",
    "    a.writerows([['schol_id','University','Major','Level','Language','Start Date','Tuition Covered', 'Accomodation covered?', 'Living Expense Covered?','Tuition fees to pay','Original Tuition fee','Accomodation to pay','Living expense to pay']])\n",
    "    for major_count in range(1,5):\n",
    "        url = 'https://www.cucas.edu.cn/china_scholarships?cat=&degree=' + str(major_count) + '&school=&program=&lang=&semester=&page='\n",
    "        iterations = page_count(url)\n",
    "        \n",
    "        for j in range(1,iterations+1):\n",
    "            url_new = url + str(j)\n",
    "            titles, majors , languages, start, scholarship, to_pay = extract(url_new)\n",
    "            for i in range(0,len(majors)):\n",
    "                title = titles[i].p.text\n",
    "                major = majors[i].p.text\n",
    "                if major_count==1:\n",
    "                    level = 'Non-Degree'\n",
    "                elif major_count==2:\n",
    "                    level = 'Bachelor'\n",
    "                elif major_count==3:\n",
    "                    level = 'Master'\n",
    "                elif major_count==4:\n",
    "                    level = 'Phd'\n",
    "                language = languages[i].text\n",
    "                start_date = start[i].text\n",
    "\n",
    "                tuition_acc_living = scholarship[i].p.text\n",
    "                tuition = tuition_acc_living[tuition_acc_living.find(':')+1:tuition_acc_living.find('\\n')].strip()\n",
    "\n",
    "                accomodation = tuition_acc_living[tuition_acc_living.find(':',tuition_acc_living.find('Accom'))+1:tuition_acc_living.find('\\n',tuition_acc_living.find('Accom'))].strip()\n",
    "\n",
    "                living = tuition_acc_living[tuition_acc_living.find(':',tuition_acc_living.find('Living'))+1:].strip()\n",
    "\n",
    "                To_Pay = to_pay[i].p.text\n",
    "                try:\n",
    "                    orig_tuition = to_pay[i].p.span.text.strip()\n",
    "                except:\n",
    "                    orig_tuition=-1\n",
    "                try:\n",
    "                    tuition_to_pay = To_Pay[To_Pay.find(':')+1:To_Pay.find('\\n',To_Pay.find(':')+1)].strip().replace(orig_tuition,'').strip()\n",
    "                except:\n",
    "                    tuition_to_pay = To_Pay[To_Pay.find(':')+1:To_Pay.find('\\n', To_Pay.find(':'))].strip()\n",
    "                \n",
    "                try:\n",
    "                    accomodation_to_pay = To_Pay[To_Pay.find(':',To_Pay.find('Acco'))+1:To_Pay.find('\\n',To_Pay.find(':',To_Pay.find('Acco')))].strip()\n",
    "                except:\n",
    "                    accomodation_to_pay = To_Pay[To_Pay.find(':',To_Pay.find('Acc'))+1:To_Pay.find('\\n',To_Pay.find('Acc'))].strip()\n",
    "                try:\n",
    "                    Living_Expense_to_pay = To_Pay[To_Pay.find(':',To_Pay.find('Expense'))+1:To_Pay.find('\\n',To_Pay.find(':',To_Pay.find('Expense')))].strip()\n",
    "                except:\n",
    "                    Living_Expense_to_pay = To_Pay[To_Pay.find(':',To_Pay.find('Liv'))+1:To_Pay.find('\\n',To_Pay.find('Liv'))].strip()\n",
    "                \n",
    "                schol_id+=1\n",
    "                data = [[schol_id,title, major,level, language, start_date,tuition,accomodation, living, tuition_to_pay, orig_tuition,accomodation_to_pay,Living_Expense_to_pay]]\n",
    "                a.writerows(data)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
